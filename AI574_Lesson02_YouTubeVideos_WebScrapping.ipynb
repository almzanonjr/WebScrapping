{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-I 574 - Natural Language Processing (FA24)\n",
    "#### **Discussion Topic for Lesson 2 (Scrapping online textual data):** *Extracting YoutTube videos captions for a certain subject*\n",
    "#### **Instructor**: Dr. Satish Srinivasan      |       **Student**:    Aureo Zanon         |       **Date**:       09/02/2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup for YouTube Captions Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and activate new conda environment (uncomment the lines below to run the conda commands)\n",
    "#!conda create -n WebScrapping python=3.10\n",
    "#!conda activate WebScrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing required Python packages (uncomment the lines below to pip install the required Python packages)\n",
    "#!pip install google-api-python-client pandas\n",
    "#!pip install google-api-python-client youtube-transcript-api pandas\n",
    "#!pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import NoTranscriptFound, TranscriptsDisabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions to Create the YouTube Data API v3 Key\n",
    "#### In order to use this Python script, you will need to create a key for the YouTube Data API v3. Please see more details at the link <https://developers.google.com/youtube/v3/getting-started>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the API Key and Building the API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube API key (Replace with your own API key)\n",
    "api_key = 'AIzaSyAGBUwif_FbvMe45dZgO2FaVr8zy5GGnL8' # I revoked this key before posting this code\n",
    "#api_key = 'YOUR_API_KEY - follow the instructions from the link above to get it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Functions to search for videos according to a certain subject and grab their captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for videos related to the subject in the last n days and capture captions\n",
    "def search_videos_last_24_hours_with_captions(query, max_results=100):\n",
    "    # Get the current UTC time and calculate the time 24 hours ago\n",
    "    n = 1\n",
    "    published_after = (datetime.now(timezone.utc) - timedelta(days=n)).isoformat()\n",
    "    \n",
    "    request = youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        q=query,\n",
    "        type=\"video\",\n",
    "        maxResults=max_results,\n",
    "        publishedAfter=published_after,\n",
    "        order=\"date\"  # Order results by date to get the latest videos\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    videos = []\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_id = item['id']['videoId']\n",
    "        video_data = {\n",
    "            \"Video Title\": item['snippet']['title'],\n",
    "            \"Channel Name\": item['snippet']['channelTitle'],\n",
    "            \"Published Date\": item['snippet']['publishedAt'],\n",
    "            \"Video ID\": video_id,\n",
    "            \"Video URL\": f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "            \"Captions\": get_video_captions(video_id)  # Capture captions\n",
    "        }\n",
    "        videos.append(video_data)\n",
    "    \n",
    "    return videos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get captions for a video\n",
    "def get_video_captions(video_id):\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        captions = \" \".join([entry['text'] for entry in transcript])\n",
    "        return captions\n",
    "    except NoTranscriptFound:\n",
    "        return \"No captions found\"\n",
    "    except TranscriptsDisabled:\n",
    "        return \"Captions are disabled for this video\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "no element found: line 1, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/WebScrapping/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[8], line 3\u001b[0m\n    videos_with_captions = search_videos_last_24_hours_with_captions(subject, max_results=100)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[6], line 27\u001b[0m in \u001b[1;35msearch_videos_last_24_hours_with_captions\u001b[0m\n    \"Captions\": get_video_captions(video_id)  # Capture captions\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[7], line 4\u001b[0m in \u001b[1;35mget_video_captions\u001b[0m\n    transcript = YouTubeTranscriptApi.get_transcript(video_id)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/WebScrapping/lib/python3.10/site-packages/youtube_transcript_api/_api.py:137\u001b[0m in \u001b[1;35mget_transcript\u001b[0m\n    return cls.list_transcripts(video_id, proxies, cookies).find_transcript(languages).fetch(preserve_formatting=preserve_formatting)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/WebScrapping/lib/python3.10/site-packages/youtube_transcript_api/_transcripts.py:292\u001b[0m in \u001b[1;35mfetch\u001b[0m\n    return _TranscriptParser(preserve_formatting=preserve_formatting).parse(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/WebScrapping/lib/python3.10/site-packages/youtube_transcript_api/_transcripts.py:358\u001b[0m in \u001b[1;35mparse\u001b[0m\n    for xml_element in ElementTree.fromstring(plain_data)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/anaconda3/envs/WebScrapping/lib/python3.10/xml/etree/ElementTree.py:1348\u001b[0;36m in \u001b[0;35mXML\u001b[0;36m\n\u001b[0;31m    return parser.close()\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>\u001b[0;36m\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m no element found: line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "# Web Scraping the captions from YouTube videos related to the selected subject\n",
    "subject = 'Elon Musk'\n",
    "videos_with_captions = search_videos_last_24_hours_with_captions(subject, max_results=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'videos_with_captions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mvideos_with_captions\u001b[49m)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerative_ai_videos_with_captions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'videos_with_captions' is not defined"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "df = pd.DataFrame(videos_with_captions)\n",
    "df.to_csv(\"generative_ai_videos_with_captions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WebScrapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
